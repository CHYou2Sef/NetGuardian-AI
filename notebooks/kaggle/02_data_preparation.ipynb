{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üîç CICIDS2017 - Dataset Pr√©-Nettoy√©\n",
                "\n",
                "**Dataset** : `/kaggle/input/cicids2017-cleaned-and-preprocessed`\n",
                "\n",
                "Ce notebook traite la version **pr√©-nettoy√©e** du CICIDS2017 avec 7 cat√©gories d'attaques.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üì¶ Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "plt.style.use('seaborn-v0_8-darkgrid')\n",
                "sns.set_palette('husl')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìÇ Charger le Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Charger le dataset pr√©-nettoy√©\n",
                "df = pd.read_csv('/kaggle/input/cicids2017-cleaned-and-preprocessed/cicids2017_cleaned.csv')\n",
                "\n",
                "print(f\"Shape: {df.shape}\")\n",
                "print(f\"Colonnes: {len(df.columns)}\")\n",
                "print(f\"Taille en m√©moire: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üîç Exploration Initiale"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Premi√®res lignes\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Informations sur les colonnes\n",
                "df.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üè∑Ô∏è Analyse des Labels"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Distribution des labels\n",
                "print(\"Distribution des types d'attaques:\")\n",
                "print(df['Attack Type'].value_counts())\n",
                "print(f\"\\nPourcentages:\")\n",
                "print(df['Attack Type'].value_counts(normalize=True) * 100)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# V√©rifier les valeurs uniques (avec longueur pour d√©tecter espaces)\n",
                "print(\"Labels uniques:\")\n",
                "for label in df['Attack Type'].unique():\n",
                "    count = (df['Attack Type'] == label).sum()\n",
                "    print(f\"  '{label}' (len={len(label)}) : {count:,} instances\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualisation\n",
                "plt.figure(figsize=(14, 6))\n",
                "df['Attack Type'].value_counts().plot(kind='bar', color='skyblue', edgecolor='black')\n",
                "plt.title('Distribution des Types d\\'Attaques - CICIDS2017 Pr√©-Nettoy√©', fontsize=16, fontweight='bold')\n",
                "plt.xlabel('Type d\\'Attaque', fontsize=12)\n",
                "plt.ylabel('Nombre d\\'Instances', fontsize=12)\n",
                "plt.xticks(rotation=45, ha='right')\n",
                "plt.grid(axis='y', alpha=0.3)\n",
                "plt.tight_layout()\n",
                "plt.savefig('attack_distribution.png', dpi=300, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üßπ V√©rification de la Qualit√©"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# V√©rifier les valeurs manquantes\n",
                "print(\"Valeurs manquantes:\")\n",
                "nan_counts = df.isnull().sum()\n",
                "if nan_counts.sum() > 0:\n",
                "    print(nan_counts[nan_counts > 0])\n",
                "else:\n",
                "    print(\"‚úÖ Aucune valeur NaN\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# V√©rifier les valeurs infinies\n",
                "print(\"Valeurs infinies:\")\n",
                "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
                "inf_counts = {}\n",
                "for col in numeric_cols:\n",
                "    inf_count = np.isinf(df[col]).sum()\n",
                "    if inf_count > 0:\n",
                "        inf_counts[col] = inf_count\n",
                "\n",
                "if inf_counts:\n",
                "    for col, count in sorted(inf_counts.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
                "        print(f\"  {col}: {count:,}\")\n",
                "else:\n",
                "    print(\"‚úÖ Aucune valeur infinie\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# V√©rifier les duplications\n",
                "dup_count = df.duplicated().sum()\n",
                "print(f\"Duplications: {dup_count:,} ({dup_count/len(df)*100:.2f}%)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üîß Nettoyage (si n√©cessaire)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Nettoyer si n√©cessaire\n",
                "df_clean = df.copy()\n",
                "\n",
                "# Remplacer infinis par NaN\n",
                "df_clean.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
                "\n",
                "# Remplir NaN avec m√©diane\n",
                "for col in df_clean.select_dtypes(include=[np.number]).columns:\n",
                "    if df_clean[col].isnull().any():\n",
                "        df_clean[col].fillna(df_clean[col].median(), inplace=True)\n",
                "\n",
                "# Supprimer duplications\n",
                "df_clean = df_clean.drop_duplicates()\n",
                "\n",
                "print(f\"‚úÖ Nettoyage termin√©\")\n",
                "print(f\"Shape finale: {df_clean.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üè∑Ô∏è Strat√©gie 1 : Classification Binaire"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cr√©er labels binaires : 0 = Normal, 1 = Attaque\n",
                "df_clean['Binary_Label'] = (df_clean['Attack Type'] != 'Normal Traffic').astype(int)\n",
                "\n",
                "print(\"Distribution binaire:\")\n",
                "print(df_clean['Binary_Label'].value_counts())\n",
                "print(f\"\\nPourcentages:\")\n",
                "print(df_clean['Binary_Label'].value_counts(normalize=True) * 100)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üè∑Ô∏è Strat√©gie 2 : Classification Multi-Classes (6 cat√©gories)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Fusionner DoS et DDoS\n",
                "df_clean['Attack_Type_Merged'] = df_clean['Attack Type'].replace({\n",
                "    'DoS': 'DoS_DDoS',\n",
                "    'DDoS': 'DoS_DDoS'\n",
                "})\n",
                "\n",
                "print(\"Distribution apr√®s fusion DoS/DDoS:\")\n",
                "print(df_clean['Attack_Type_Merged'].value_counts())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Encoder les labels\n",
                "le = LabelEncoder()\n",
                "df_clean['Label_Encoded'] = le.fit_transform(df_clean['Attack_Type_Merged'])\n",
                "\n",
                "# Afficher le mapping\n",
                "print(\"Mapping num√©rique:\")\n",
                "for i, label in enumerate(le.classes_):\n",
                "    count = (df_clean['Label_Encoded'] == i).sum()\n",
                "    print(f\"{i}: {label} ({count:,} instances)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üéØ Pr√©paration des Features"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# S√©parer features et labels\n",
                "label_cols = ['Attack Type', 'Attack_Type_Merged', 'Label_Encoded', 'Binary_Label']\n",
                "feature_cols = [col for col in df_clean.columns if col not in label_cols]\n",
                "\n",
                "X = df_clean[feature_cols]\n",
                "y = df_clean['Label_Encoded']  # Ou 'Binary_Label' pour classification binaire\n",
                "\n",
                "print(f\"Features shape: {X.shape}\")\n",
                "print(f\"Labels shape: {y.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Normaliser les features\n",
                "scaler = StandardScaler()\n",
                "X_scaled = scaler.fit_transform(X)\n",
                "\n",
                "print(f\"‚úÖ Features normalis√©es\")\n",
                "print(f\"Shape: {X_scaled.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üíæ Sauvegarder les R√©sultats"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Sauvegarder le dataset complet\n",
                "df_clean.to_csv('cicids2017_final.csv', index=False)\n",
                "print(\"‚úÖ Dataset complet sauvegard√©: cicids2017_final.csv\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Sauvegarder X et y pour ML\n",
                "np.save('X_scaled.npy', X_scaled)\n",
                "np.save('y.npy', y.values)\n",
                "print(\"‚úÖ Features et labels sauvegard√©s: X_scaled.npy, y.npy\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Sauvegarder les encodeurs\n",
                "import joblib\n",
                "\n",
                "joblib.dump(le, 'label_encoder.pkl')\n",
                "joblib.dump(scaler, 'scaler.pkl')\n",
                "print(\"‚úÖ Encodeurs sauvegard√©s: label_encoder.pkl, scaler.pkl\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìä Statistiques Finales"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 70)\n",
                "print(\"R√âSUM√â DU PREPROCESSING\")\n",
                "print(\"=\" * 70)\n",
                "print(f\"\\nDataset final:\")\n",
                "print(f\"  - Lignes: {df_clean.shape[0]:,}\")\n",
                "print(f\"  - Features: {X.shape[1]}\")\n",
                "print(f\"  - Classes: {len(le.classes_)}\")\n",
                "print(f\"\\nDistribution des classes:\")\n",
                "for i, label in enumerate(le.classes_):\n",
                "    count = (y == i).sum()\n",
                "    pct = (count / len(y)) * 100\n",
                "    print(f\"  {i}: {label:20s} {count:8,} ({pct:5.2f}%)\")\n",
                "print(\"\\n\" + \"=\" * 70)\n",
                "print(\"‚úÖ Preprocessing termin√©! Pr√™t pour l'entra√Ænement.\")\n",
                "print(\"=\" * 70)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üì• Prochaines √âtapes\n",
                "\n",
                "1. ‚úÖ Dataset explor√© et nettoy√©\n",
                "2. ‚úÖ Labels encod√©s (binaire ou multi-classes)\n",
                "3. ‚úÖ Features normalis√©es\n",
                "4. ‚úÖ Fichiers sauvegard√©s\n",
                "\n",
                "**√Ä faire ensuite :**\n",
                "- T√©l√©charger les fichiers depuis Kaggle Output\n",
                "- Placer dans `data/processed/` de votre projet local\n",
                "- Commit sur Git\n",
                "- Passer au Training ML/DL !\n",
                "\n",
                "---\n",
                "\n",
                "**Bon entra√Ænement ! üöÄ**"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
