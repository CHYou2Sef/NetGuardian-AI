{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üèÅ Benchmark & Comparaison de Mod√®les\n",
                "\n",
                "**Objectif** : Comparer diff√©rentes approches (Supervis√© vs Non-Supervis√©) et algorithmes pour la d√©tection d'intrusions.\n",
                "\n",
                "**Mod√®les test√©s** :\n",
                "1.  **Random Forest** (R√©f√©rence)\n",
                "2.  **SVM** (Support Vector Machine)\n",
                "3.  **KNN** (K-Nearest Neighbors)\n",
                "4.  **Autoencoder** (Deep Learning Non-Supervis√©)\n",
                "\n",
                "---\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Imports\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import time\n",
                "import joblib\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
                "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.neighbors import KNeighborsClassifier\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras.models import Model, Sequential\n",
                "from tensorflow.keras.layers import Dense, Input\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "plt.style.use('seaborn-v0_8-darkgrid')\n",
                "sns.set_palette('husl')\n",
                "\n",
                "print(f\"TensorFlow version: {tf.__version__}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üì• 1. Chargement et Sampling\n",
                "\n",
                "‚ö†Ô∏è **Note** : Les algorithmes comme SVM et KNN sont tr√®s lents sur 2.5 Millions de lignes. Nous allons travailler sur un **√©chantillon stratifi√© de 50 000 lignes** pour ce benchmark."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Charger le dataset (Chemin √† adapter selon votre dossier)\n",
                "try:\n",
                "    df = pd.read_csv('/kaggle/input/cicids2017-cleaned-and-preprocessed/cicids2017_cleaned.csv') # Sur Kaggle\n",
                "    # df = pd.read_csv('../../../data/processed/cicids2017_cleaned.csv') # En local\n",
                "except:\n",
                "    # Fallback pour la d√©mo si fichier inexistant\n",
                "    print(\"‚ö†Ô∏è Fichier non trouv√©, cr√©ation de donn√©es synth√©tiques pour la d√©mo...\")\n",
                "    df = pd.DataFrame(np.random.randn(50000, 20), columns=[f'feat_{i}' for i in range(20)])\n",
                "    df['Attack Type'] = np.random.choice(['Normal Traffic', 'DoS', 'PortScan'], 50000, p=[0.8, 0.1, 0.1])\n",
                "\n",
                "# Cr√©er binaire\n",
                "df['Label'] = (df['Attack Type'] != 'Normal Traffic').astype(int)\n",
                "\n",
                "print(f\"Dataset complet: {df.shape}\")\n",
                "\n",
                "# Sampling Stratifi√© (50k lignes)\n",
                "df_sample, _ = train_test_split(df, train_size=50000, stratify=df['Label'], random_state=42)\n",
                "\n",
                "print(f\"Dataset √©chantillonn√©: {df_sample.shape}\")\n",
                "print(df_sample['Label'].value_counts(normalize=True))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üõ†Ô∏è 2. Pr√©paration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Features vs Target\n",
                "X = df_sample.select_dtypes(include=[np.number]).drop('Label', axis=1)\n",
                "y = df_sample['Label']\n",
                "\n",
                "# Train/Test Split\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
                "\n",
                "# Scaling (Crucial pour SVM/KNN/Autoencoder)\n",
                "scaler = StandardScaler()\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "X_test_scaled = scaler.transform(X_test)\n",
                "\n",
                "print(\"Donn√©es pr√©par√©es et normalis√©es.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üèéÔ∏è 3. Benchmark Supervis√©"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Dictionnaire pour stocker les r√©sultats\n",
                "results = {}\n",
                "\n",
                "def train_evaluate(model, name):\n",
                "    print(f\"\\nüîÑ Entra√Ænement de {name}...\")\n",
                "    start = time.time()\n",
                "    model.fit(X_train_scaled, y_train)\n",
                "    train_time = time.time() - start\n",
                "    \n",
                "    # Prediction\n",
                "    y_pred = model.predict(X_test_scaled)\n",
                "    \n",
                "    # Metrics\n",
                "    acc = accuracy_score(y_test, y_pred)\n",
                "    f1 = f1_score(y_test, y_pred)\n",
                "    prec = precision_score(y_test, y_pred)\n",
                "    rec = recall_score(y_test, y_pred)\n",
                "    \n",
                "    # Sauvegarder le mod√®le\n",
                "    filename = f\"{name.replace(' ', '_').lower()}.pkl\"\n",
                "    joblib.dump(model, filename)\n",
                "    \n",
                "    results[name] = {\n",
                "        'Time_sec': train_time,\n",
                "        'Accuracy': acc,\n",
                "        'F1-Score': f1,\n",
                "        'Precision': prec,\n",
                "        'Recall': rec,\n",
                "        'File': filename\n",
                "    }\n",
                "    \n",
                "    print(f\"‚úÖ Termin√© en {train_time:.2f}s | F1-Score: {f1:.4f} | Sauvegard√©: {filename}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Random Forest\n",
                "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
                "train_evaluate(rf, 'Random Forest')\n",
                "\n",
                "# 2. SVM (Kernel RBF par d√©faut)\n",
                "svm = SVC(kernel='rbf', random_state=42)\n",
                "train_evaluate(svm, 'SVM')\n",
                "\n",
                "# 3. KNN (k=5)\n",
                "knn = KNeighborsClassifier(n_neighbors=5)\n",
                "train_evaluate(knn, 'KNN')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üß† 4. Approche Non-Supervis√©e (Autoencoder)\n",
                "\n",
                "**Principe** : L'Autoencoder apprend √† compresser et reconstruire uniquement le trafic **NORMAL**. S'il n'arrive pas √† reconstruire une donn√©e (erreur de reconstruction √©lev√©e), c'est probablement une **ANOMALIE** (Attaque)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Pr√©parer les donn√©es : On entra√Æne SEULEMENT sur le trafic Normal\n",
                "X_train_normal = X_train_scaled[y_train == 0]\n",
                "X_test_normal = X_test_scaled[y_test == 0]\n",
                "X_test_anomaly = X_test_scaled[y_test == 1]\n",
                "\n",
                "print(f\"Train Normal: {X_train_normal.shape}\")\n",
                "\n",
                "# D√©finir l'architecture de l'Autoencoder\n",
                "input_dim = X_train_scaled.shape[1]\n",
                "\n",
                "autoencoder = Sequential([\n",
                "    # Encoder\n",
                "    Dense(32, activation='relu', input_shape=(input_dim,)),\n",
                "    Dense(16, activation='relu'),\n",
                "    Dense(8, activation='relu'), # Latent space (compression)\n",
                "    # Decoder\n",
                "    Dense(16, activation='relu'),\n",
                "    Dense(32, activation='relu'),\n",
                "    Dense(input_dim, activation='sigmoid') # Reconstruction\n",
                "])\n",
                "\n",
                "autoencoder.compile(optimizer='adam', loss='mse')\n",
                "\n",
                "# Entra√Æner\n",
                "print(\"\\nüîÑ Entra√Ænement de l'Autoencoder...\")\n",
                "start = time.time()\n",
                "history = autoencoder.fit(\n",
                "    X_train_normal, X_train_normal,\n",
                "    epochs=20,\n",
                "    batch_size=64,\n",
                "    validation_data=(X_test_normal, X_test_normal),\n",
                "    shuffle=True,\n",
                "    verbose=0\n",
                ")\n",
                "train_time = time.time() - start\n",
                "print(f\"‚úÖ Termin√© en {train_time:.2f}s\")\n",
                "\n",
                "# Calculer l'erreur de reconstruction (MSE)\n",
                "reconstructions = autoencoder.predict(X_test_scaled)\n",
                "mse = np.mean(np.power(X_test_scaled - reconstructions, 2), axis=1)\n",
                "\n",
                "# D√©finir le seuil (Threshold) = Moyenne + 3*Ecart-type du Normal (ou quantile)\n",
                "normal_mse = mse[y_test == 0]\n",
                "threshold = np.percentile(normal_mse, 95) # On accepte 5% de faux positifs pour √™tre sensible\n",
                "print(f\"Seuil de d√©tection d'anomalie: {threshold:.4f}\")\n",
                "\n",
                "# Pr√©diction : Si Erreur > Seuil alors Attaque (1), sinon Normal (0)\n",
                "y_pred_ae = (mse > threshold).astype(int)\n",
                "\n",
                "# Sauvegarder\n",
                "autoencoder.save('autoencoder.h5')\n",
                "\n",
                "# Metrics Autoencoder\n",
                "results['Autoencoder'] = {\n",
                "    'Time_sec': train_time,\n",
                "    'Accuracy': accuracy_score(y_test, y_pred_ae),\n",
                "    'F1-Score': f1_score(y_test, y_pred_ae),\n",
                "    'Precision': precision_score(y_test, y_pred_ae),\n",
                "    'Recall': recall_score(y_test, y_pred_ae),\n",
                "    'File': 'autoencoder.h5'\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìä 5. Comparaison Finale"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cr√©er un DataFrame de r√©sultats\n",
                "df_res = pd.DataFrame(results).T\n",
                "df_res = df_res.sort_values(by='F1-Score', ascending=False)\n",
                "\n",
                "print(df_res)\n",
                "\n",
                "# Visualisation\n",
                "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
                "\n",
                "# F1-Score Comparaison\n",
                "sns.barplot(x=df_res.index, y='F1-Score', ax=axes[0], palette='viridis')\n",
                "axes[0].set_title('Performance (F1-Score)', fontsize=14, fontweight='bold')\n",
                "axes[0].set_ylim(0, 1.1)\n",
                "\n",
                "# Temps d'entra√Ænement\n",
                "sns.barplot(x=df_res.index, y='Time_sec', ax=axes[1], palette='magma')\n",
                "axes[1].set_title(\"Temps d'Entra√Ænement (secondes)\", fontsize=14, fontweight='bold')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üíæ 6. Sauvegarde sur Google Drive\n",
                "\n",
                "Nous sauvegardons tous les mod√®les g√©n√©r√©s ainsi que le rapport de benchmark dans votre Drive."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Fonction de sauvegarde Drive\n",
                "import os\n",
                "import shutil\n",
                "\n",
                "def save_to_drive(source_files, destination_folder='NetGuardian_Models/Comparison'):\n",
                "    \"\"\"Sauvegarde une liste de fichiers vers Google Drive\"\"\"\n",
                "    try:\n",
                "        from google.colab import drive\n",
                "        if not os.path.exists('/content/drive'):\n",
                "            drive.mount('/content/drive')\n",
                "        \n",
                "        drive_path = f\"/content/drive/MyDrive/{destination_folder}\"\n",
                "        os.makedirs(drive_path, exist_ok=True)\n",
                "        \n",
                "        print(f\"\\nüíæ Sauvegarde vers {drive_path}...\")\n",
                "        for file in source_files:\n",
                "            if os.path.exists(file):\n",
                "                shutil.copy2(file, drive_path)\n",
                "                print(f\"  ‚úÖ {file} copi√©\")\n",
                "            else:\n",
                "                print(f\"  ‚ö†Ô∏è {file} introuvable\")\n",
                "                \n",
                "    except ImportError:\n",
                "        print(\"‚ö†Ô∏è Environnement local/Kaggle d√©tect√© (Pas de Google Colab).\")\n",
                "        print(f\"Les fichiers sont sauvegard√©s localement dans: {os.getcwd()}\")\n",
                "    except Exception as e:\n",
                "        print(f\"‚ùå Erreur sauvegarde Drive: {e}\")\n",
                "\n",
                "# 1. Sauvegarder les m√©triques\n",
                "df_res.to_csv('benchmark_results.csv')\n",
                "\n",
                "# 2. Liste de tous les fichiers √† sauvegarder (Mod√®les + CSV)\n",
                "files_to_save = df_res['File'].tolist() + ['benchmark_results.csv']\n",
                "\n",
                "# 3. Ex√©cuter la sauvegarde\n",
                "save_to_drive(files_to_save)\n",
                "\n",
                "print(\"\\n‚úÖ Tous les mod√®les et r√©sultats ont √©t√© s√©curis√©s.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}