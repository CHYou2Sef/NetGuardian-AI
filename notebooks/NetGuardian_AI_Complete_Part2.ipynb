{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üõ°Ô∏è NetGuardian-AI: Complete IDS Pipeline (Part 2)\n",
                "\n",
                "**Phases 4-7: Model Training, Evaluation, Simulation & Comparison**\n",
                "\n",
                "This notebook continues from Part 1 with:\n",
                "- Phase 4: Hybrid Model Training\n",
                "- Phase 5: Model Evaluation\n",
                "- Phase 6: Real-Time Simulation\n",
                "- Phase 7: Model Comparison\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<a id='phase4'></a>\n",
                "## üéØ Phase 4: Hybrid Model Training\n",
                "\n",
                "**Purpose**: Train a two-stage hybrid IDS system.\n",
                "\n",
                "**Architecture**:\n",
                "1. **Model 1 (Binary)**: Detects if traffic is normal or malicious\n",
                "2. **Model 2 (Multi-Class)**: Identifies the specific attack type\n",
                "\n",
                "**Why Hybrid?**\n",
                "- **Faster**: Binary detection is quick, multi-class only runs on detected attacks\n",
                "- **More Accurate**: Each model specializes in its task\n",
                "- **Scalable**: Can handle high-volume traffic efficiently"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 4.1: Train Binary Detection Model\n",
                "\n",
                "**Explanation**: XGBoost is chosen for its:\n",
                "- **Speed**: Fast training and prediction\n",
                "- **Accuracy**: Handles complex patterns well\n",
                "- **Imbalance handling**: `scale_pos_weight` parameter balances classes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate class weight for imbalanced data\n",
                "scale_pos_weight = len(y_binary_train[y_binary_train==0]) / len(y_binary_train[y_binary_train==1])\n",
                "print(f\"Scale pos weight: {scale_pos_weight:.2f}\")\n",
                "\n",
                "# Train binary classifier\n",
                "print(\"\\nüöÄ Training Model 1 (Binary Detection)...\")\n",
                "model1 = XGBClassifier(\n",
                "    n_estimators=200,        # Number of trees\n",
                "    max_depth=10,            # Maximum tree depth\n",
                "    learning_rate=0.1,       # Step size shrinkage\n",
                "    scale_pos_weight=scale_pos_weight,  # Handle class imbalance\n",
                "    random_state=42,\n",
                "    n_jobs=-1                # Use all CPU cores\n",
                ")\n",
                "\n",
                "model1.fit(X_train_scaled, y_binary_train)\n",
                "print(\"‚úÖ Model 1 trained successfully\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 4.2: Evaluate Binary Model\n",
                "\n",
                "**Explanation**: We evaluate using multiple metrics:\n",
                "- **Precision**: Of predicted attacks, how many are real?\n",
                "- **Recall**: Of real attacks, how many did we catch?\n",
                "- **F1-Score**: Harmonic mean of precision and recall\n",
                "- **AUC-ROC**: Overall discrimination ability"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Make predictions\n",
                "y_binary_pred = model1.predict(X_test_scaled)\n",
                "y_binary_proba = model1.predict_proba(X_test_scaled)[:, 1]\n",
                "\n",
                "# Evaluation\n",
                "print(\"=\"*70)\n",
                "print(\"MODEL 1: BINARY DETECTION\")\n",
                "print(\"=\"*70)\n",
                "print(classification_report(y_binary_test, y_binary_pred, target_names=['Normal', 'Attack']))\n",
                "\n",
                "# AUC-ROC\n",
                "auc = roc_auc_score(y_binary_test, y_binary_proba)\n",
                "print(f\"\\nAUC-ROC: {auc:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Confusion matrix visualization\n",
                "cm = confusion_matrix(y_binary_test, y_binary_pred)\n",
                "\n",
                "plt.figure(figsize=(8, 6))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
                "            xticklabels=['Normal', 'Attack'],\n",
                "            yticklabels=['Normal', 'Attack'])\n",
                "plt.title('Confusion Matrix - Binary Detection', fontsize=14, fontweight='bold')\n",
                "plt.ylabel('True Label')\n",
                "plt.xlabel('Predicted Label')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 4.3: Train Multi-Class Model with SMOTE\n",
                "\n",
                "**Explanation**: \n",
                "- We train only on detected attacks (not normal traffic)\n",
                "- **SMOTE** (Synthetic Minority Over-sampling Technique) creates synthetic samples for minority classes\n",
                "- This balances the dataset and improves detection of rare attacks"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Filter only attacks for training\n",
                "attack_mask_train = y_binary_train == 1\n",
                "X_train_attacks = X_train_scaled[attack_mask_train]\n",
                "y_multi_train_attacks = y_multi_train[attack_mask_train]\n",
                "\n",
                "print(f\"Attack samples for training: {X_train_attacks.shape}\")\n",
                "print(f\"\\nClass distribution before SMOTE:\")\n",
                "print(y_multi_train_attacks.value_counts())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Apply SMOTE to balance classes\n",
                "print(\"\\nüîÑ Applying SMOTE...\")\n",
                "smote = SMOTE(random_state=42, k_neighbors=5)\n",
                "X_train_resampled, y_multi_resampled = smote.fit_resample(X_train_attacks, y_multi_train_attacks)\n",
                "\n",
                "print(f\"‚úÖ After SMOTE: {X_train_resampled.shape}\")\n",
                "print(f\"\\nClass distribution after SMOTE:\")\n",
                "print(pd.Series(y_multi_resampled).value_counts())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train multi-class classifier\n",
                "print(\"\\nüöÄ Training Model 2 (Multi-Class Classification)...\")\n",
                "model2 = XGBClassifier(\n",
                "    n_estimators=300,\n",
                "    max_depth=12,\n",
                "    learning_rate=0.1,\n",
                "    random_state=42,\n",
                "    n_jobs=-1\n",
                ")\n",
                "\n",
                "model2.fit(X_train_resampled, y_multi_resampled)\n",
                "print(\"‚úÖ Model 2 trained successfully\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 4.4: Evaluate Multi-Class Model\n",
                "\n",
                "**Explanation**: We evaluate only on attack samples from the test set to see how well we classify different attack types."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluate on test attacks\n",
                "attack_mask_test = y_binary_test == 1\n",
                "X_test_attacks = X_test_scaled[attack_mask_test]\n",
                "y_multi_test_attacks = y_multi_test[attack_mask_test]\n",
                "\n",
                "y_multi_pred = model2.predict(X_test_attacks)\n",
                "\n",
                "print(\"=\"*70)\n",
                "print(\"MODEL 2: MULTI-CLASS CLASSIFICATION\")\n",
                "print(\"=\"*70)\n",
                "print(classification_report(y_multi_test_attacks, y_multi_pred, target_names=le.classes_))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Multi-class confusion matrix\n",
                "cm_multi = confusion_matrix(y_multi_test_attacks, y_multi_pred)\n",
                "\n",
                "plt.figure(figsize=(10, 8))\n",
                "sns.heatmap(cm_multi, annot=True, fmt='d', cmap='YlOrRd',\n",
                "            xticklabels=le.classes_,\n",
                "            yticklabels=le.classes_)\n",
                "plt.title('Confusion Matrix - Multi-Class', fontsize=14, fontweight='bold')\n",
                "plt.ylabel('True Label')\n",
                "plt.xlabel('Predicted Label')\n",
                "plt.xticks(rotation=45, ha='right')\n",
                "plt.yticks(rotation=0)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 4.5: Create Hybrid IDS Class\n",
                "\n",
                "**Explanation**: This class combines both models into a single prediction pipeline:\n",
                "1. **Step 1**: Binary model checks if traffic is malicious\n",
                "2. **Step 2**: If malicious, multi-class model identifies the attack type"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class HybridIDS:\n",
                "    \"\"\"\n",
                "    Two-stage hybrid intrusion detection system\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self, binary_model, multiclass_model, scaler, label_encoder):\n",
                "        self.binary_model = binary_model\n",
                "        self.multiclass_model = multiclass_model\n",
                "        self.scaler = scaler\n",
                "        self.le = label_encoder\n",
                "    \n",
                "    def predict(self, X):\n",
                "        \"\"\"\n",
                "        Two-stage prediction\n",
                "        \n",
                "        Args:\n",
                "            X: Features (DataFrame or array)\n",
                "        \n",
                "        Returns:\n",
                "            List of prediction dictionaries\n",
                "        \"\"\"\n",
                "        # Normalize\n",
                "        X_scaled = self.scaler.transform(X)\n",
                "        \n",
                "        # Stage 1: Binary detection\n",
                "        is_attack = self.binary_model.predict(X_scaled)\n",
                "        binary_proba = self.binary_model.predict_proba(X_scaled)\n",
                "        \n",
                "        results = []\n",
                "        \n",
                "        for i, (attack_flag, proba) in enumerate(zip(is_attack, binary_proba)):\n",
                "            if attack_flag == 0:\n",
                "                # Normal traffic\n",
                "                results.append({\n",
                "                    'type': 'Normal_Traffic',\n",
                "                    'confidence': float(proba[0]),\n",
                "                    'is_attack': False\n",
                "                })\n",
                "            else:\n",
                "                # Attack detected ‚Üí Stage 2: Classify\n",
                "                attack_type_encoded = self.multiclass_model.predict(X_scaled[i:i+1])[0]\n",
                "                attack_proba = self.multiclass_model.predict_proba(X_scaled[i:i+1])[0]\n",
                "                attack_type = self.le.inverse_transform([attack_type_encoded])[0]\n",
                "                \n",
                "                results.append({\n",
                "                    'type': attack_type,\n",
                "                    'confidence': float(attack_proba.max()),\n",
                "                    'is_attack': True\n",
                "                })\n",
                "        \n",
                "        return results\n",
                "    \n",
                "    def predict_df(self, X):\n",
                "        \"\"\"Return predictions as DataFrame\"\"\"\n",
                "        results = self.predict(X)\n",
                "        return pd.DataFrame(results)\n",
                "\n",
                "print(\"‚úÖ HybridIDS class created\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 4.6: Test Hybrid System\n",
                "\n",
                "**Explanation**: We test the complete hybrid system on a sample to verify it works correctly."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create hybrid system\n",
                "hybrid_ids = HybridIDS(\n",
                "    binary_model=model1,\n",
                "    multiclass_model=model2,\n",
                "    scaler=scaler,\n",
                "    label_encoder=le\n",
                ")\n",
                "\n",
                "# Test on sample\n",
                "sample_size = 100\n",
                "X_sample = X_test.iloc[:sample_size]\n",
                "y_true = df_clean.loc[X_sample.index, 'Attack_Type']\n",
                "\n",
                "# Predictions\n",
                "predictions = hybrid_ids.predict_df(X_sample)\n",
                "\n",
                "# Compare with ground truth\n",
                "comparison = pd.DataFrame({\n",
                "    'True_Label': y_true.values,\n",
                "    'Predicted_Label': predictions['type'].values,\n",
                "    'Confidence': predictions['confidence'].values,\n",
                "    'Is_Attack': predictions['is_attack'].values\n",
                "})\n",
                "\n",
                "print(\"Sample predictions:\")\n",
                "display(comparison.head(20))\n",
                "\n",
                "# Calculate accuracy\n",
                "correct = (comparison['True_Label'] == comparison['Predicted_Label']).sum()\n",
                "accuracy = correct / len(comparison) * 100\n",
                "\n",
                "print(f\"\\n{'='*70}\")\n",
                "print(f\"HYBRID SYSTEM PERFORMANCE\")\n",
                "print(f\"{'='*70}\")\n",
                "print(f\"Accuracy: {accuracy:.2f}%\")\n",
                "print(f\"Correct predictions: {correct}/{len(comparison)}\")\n",
                "print(f\"{'='*70}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 4.7: Save Models\n",
                "\n",
                "**Explanation**: We save all components for deployment and future use."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save individual models\n",
                "joblib.dump(model1, 'model1_binary.pkl')\n",
                "joblib.dump(model2, 'model2_multiclass.pkl')\n",
                "\n",
                "# Save complete system\n",
                "import pickle\n",
                "hybrid_system = {\n",
                "    'binary_model': model1,\n",
                "    'multiclass_model': model2,\n",
                "    'scaler': scaler,\n",
                "    'label_encoder': le,\n",
                "    'feature_names': X.columns.tolist()\n",
                "}\n",
                "\n",
                "with open('hybrid_ids_system.pkl', 'wb') as f:\n",
                "    pickle.dump(hybrid_system, f)\n",
                "\n",
                "print(\"‚úÖ All models saved successfully\")\n",
                "print(\"\\nFiles created:\")\n",
                "print(\"  - model1_binary.pkl\")\n",
                "print(\"  - model2_multiclass.pkl\")\n",
                "print(\"  - hybrid_ids_system.pkl\")\n",
                "print(\"  - scaler.pkl\")\n",
                "print(\"  - label_encoder.pkl\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<a id='phase5'></a>\n",
                "## üìä Phase 5: Model Evaluation & Robustness\n",
                "\n",
                "**Purpose**: Thoroughly evaluate the hybrid system.\n",
                "\n",
                "**What this phase does**:\n",
                "1. Evaluates performance on clean test data\n",
                "2. Tests robustness against noisy data (simulating real-world conditions)\n",
                "3. Analyzes error patterns\n",
                "4. Identifies weaknesses for improvement"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 5.1: Robustness Testing\n",
                "\n",
                "**Explanation**: Real-world network traffic is never as clean as our dataset. We add Gaussian noise to simulate:\n",
                "- Network jitter\n",
                "- Measurement errors\n",
                "- Hardware variations\n",
                "\n",
                "A robust model should maintain performance even with noise."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def add_noise(X, noise_level=0.1):\n",
                "    \"\"\"\n",
                "    Add Gaussian noise to features\n",
                "    \n",
                "    Args:\n",
                "        X: Feature array\n",
                "        noise_level: Standard deviation of noise (as fraction of feature std)\n",
                "    \n",
                "    Returns:\n",
                "        Noisy feature array\n",
                "    \"\"\"\n",
                "    noise = np.random.normal(0, noise_level, X.shape)\n",
                "    X_noisy = X + noise * X.std().values\n",
                "    return X_noisy\n",
                "\n",
                "# Test with different noise levels\n",
                "noise_levels = [0.0, 0.1, 0.2, 0.5]  # 0%, 10%, 20%, 50%\n",
                "accuracies = []\n",
                "\n",
                "print(\"üõ°Ô∏è Robustness Testing...\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "# Get ground truth\n",
                "y_true_merged = df_clean.loc[X_test.index, 'Attack_Merged']\n",
                "\n",
                "for nl in noise_levels:\n",
                "    X_noisy = add_noise(X_test, noise_level=nl)\n",
                "    res_noisy = hybrid_ids.predict_df(X_noisy)\n",
                "    acc = accuracy_score(y_true_merged, res_noisy['type'])\n",
                "    accuracies.append(acc)\n",
                "    print(f\"Noise {nl*100:3.0f}% ‚Üí Accuracy: {acc:.2%}\")\n",
                "\n",
                "print(\"=\"*50)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize robustness\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.plot(noise_levels, accuracies, marker='o', linestyle='-', color='red', linewidth=2, markersize=8)\n",
                "plt.title('Model Robustness vs Noise Level', fontsize=14, fontweight='bold')\n",
                "plt.xlabel('Noise Level (fraction of std)', fontsize=12)\n",
                "plt.ylabel('Accuracy', fontsize=12)\n",
                "plt.grid(True, alpha=0.3)\n",
                "plt.ylim([0, 1.1])\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(\"\\nüìä Interpretation:\")\n",
                "print(\"- If accuracy stays >90% with 10% noise: Excellent robustness\")\n",
                "print(\"- If accuracy drops <80% with 20% noise: Model may struggle in real-world\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 5.2: Error Analysis\n",
                "\n",
                "**Explanation**: Understanding where the model fails helps us improve it. We analyze:\n",
                "- Which attack types are confused with each other\n",
                "- False positives (normal traffic flagged as attack)\n",
                "- False negatives (attacks missed)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Analyze errors\n",
                "predictions_full = hybrid_ids.predict_df(X_test)\n",
                "results_df = pd.DataFrame({\n",
                "    'True_Label': y_true_merged.values,\n",
                "    'Predicted_Label': predictions_full['type'].values\n",
                "})\n",
                "\n",
                "# Find errors\n",
                "errors = results_df[results_df['True_Label'] != results_df['Predicted_Label']]\n",
                "\n",
                "print(f\"Total errors: {len(errors):,} out of {len(results_df):,} ({len(errors)/len(results_df)*100:.2f}%)\")\n",
                "print(\"\\nTop 5 confusion pairs (True ‚Üí Predicted):\")\n",
                "confusion_counts = errors.groupby(['True_Label', 'Predicted_Label']).size().sort_values(ascending=False).head(5)\n",
                "print(confusion_counts)\n",
                "\n",
                "print(\"\\nüí° Insights:\")\n",
                "print(\"- If DoS_DDoS ‚Üî PortScan confusion: These attacks have similar network patterns\")\n",
                "print(\"- If Normal ‚Üí Attack: False positives (may annoy users)\")\n",
                "print(\"- If Attack ‚Üí Normal: False negatives (CRITICAL security risk!)\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}