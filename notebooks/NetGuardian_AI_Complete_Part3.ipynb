{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üõ°Ô∏è NetGuardian-AI: Complete IDS Pipeline (Part 3)\n",
                "\n",
                "**Phases 6-7: Real-Time Simulation & Model Comparison**\n",
                "\n",
                "This final part covers:\n",
                "- Phase 6: Real-Time Simulation\n",
                "- Phase 7: Model Comparison Benchmark\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<a id='phase6'></a>\n",
                "## üö® Phase 6: Real-Time Simulation\n",
                "\n",
                "**Purpose**: Simulate real-world deployment of the IDS.\n",
                "\n",
                "**What this phase does**:\n",
                "- Simulates packet-by-packet processing\n",
                "- Generates real-time alerts for detected attacks\n",
                "- Demonstrates the system's operational behavior\n",
                "- Provides statistics on detection performance"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 6.1: Prepare Simulation Data\n",
                "\n",
                "**Explanation**: We create a stream of network packets (mix of normal and malicious) to simulate real-time traffic."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from IPython.display import display, clear_output\n",
                "import time\n",
                "\n",
                "# Sample random packets for simulation\n",
                "stream_data = df_clean.sample(n=50, random_state=42).reset_index(drop=True)\n",
                "\n",
                "# Prepare features (exclude labels)\n",
                "label_cols = ['Attack_Type', 'Binary_Label', 'Attack_Merged', 'Multiclass_Label']\n",
                "features_to_predict = stream_data.drop(label_cols, axis=1, errors='ignore')\n",
                "\n",
                "print(f\"‚úÖ Prepared {len(stream_data)} packets for simulation\")\n",
                "print(f\"\\nPacket distribution:\")\n",
                "print(stream_data['Attack_Type'].value_counts())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 6.2: Run Real-Time Simulation\n",
                "\n",
                "**Explanation**: This simulates the IDS processing packets one by one:\n",
                "- **Green alerts**: Normal traffic (no action needed)\n",
                "- **Red alerts**: Attack detected (security team notified)\n",
                "- **Confidence score**: How certain the model is\n",
                "\n",
                "In production, this would run continuously on live network traffic."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"üü¢ Starting NetGuardian-AI Real-Time Monitor...\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "history = []\n",
                "attack_count = 0\n",
                "normal_count = 0\n",
                "\n",
                "for i in range(len(stream_data)):\n",
                "    # Extract one packet\n",
                "    packet_features = features_to_predict.iloc[i:i+1]\n",
                "    true_label = stream_data.iloc[i]['Attack_Type']\n",
                "    \n",
                "    # Predict\n",
                "    prediction = hybrid_ids.predict(packet_features)[0]\n",
                "    \n",
                "    # Display alert\n",
                "    if prediction['is_attack']:\n",
                "        attack_count += 1\n",
                "        print(f\"\\033[91müö® [PACKET {i:03d}] ATTACK DETECTED: {prediction['type']} \"\n",
                "              f\"(Confidence: {prediction['confidence']:.2%}) | True: {true_label}\\033[0m\")\n",
                "    else:\n",
                "        normal_count += 1\n",
                "        if i % 5 == 0:  # Print every 5th normal packet to reduce clutter\n",
                "            print(f\"\\033[92m‚úÖ [PACKET {i:03d}] Normal Traffic | True: {true_label}\\033[0m\")\n",
                "    \n",
                "    # Store for statistics\n",
                "    history.append({\n",
                "        'packet_id': i,\n",
                "        'predicted': prediction['type'],\n",
                "        'true': true_label,\n",
                "        'confidence': prediction['confidence'],\n",
                "        'is_attack': prediction['is_attack']\n",
                "    })\n",
                "    \n",
                "    # Simulate real-time delay\n",
                "    time.sleep(0.05)\n",
                "\n",
                "print(\"=\"*60)\n",
                "print(\"üèÅ Simulation Complete\")\n",
                "print(f\"\\nSummary:\")\n",
                "print(f\"  Total packets processed: {len(stream_data)}\")\n",
                "print(f\"  Normal traffic: {normal_count}\")\n",
                "print(f\"  Attacks detected: {attack_count}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 6.3: Session Statistics\n",
                "\n",
                "**Explanation**: Analyze the simulation results to understand detection performance."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Convert to DataFrame for analysis\n",
                "history_df = pd.DataFrame(history)\n",
                "\n",
                "# Detection statistics\n",
                "print(\"üìä Detection Statistics:\")\n",
                "print(\"\\nPredicted attack types:\")\n",
                "print(history_df['predicted'].value_counts())\n",
                "\n",
                "# Accuracy\n",
                "correct = (history_df['predicted'] == history_df['true']).sum()\n",
                "accuracy = correct / len(history_df) * 100\n",
                "\n",
                "print(f\"\\n‚úÖ Accuracy: {accuracy:.2f}% ({correct}/{len(history_df)} correct)\")\n",
                "\n",
                "# Average confidence\n",
                "avg_confidence = history_df['confidence'].mean()\n",
                "print(f\"üìà Average Confidence: {avg_confidence:.2%}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<a id='phase7'></a>\n",
                "## üèÜ Phase 7: Model Comparison Benchmark\n",
                "\n",
                "**Purpose**: Compare different ML approaches for IDS.\n",
                "\n",
                "**Models Tested**:\n",
                "1. **Random Forest**: Ensemble of decision trees\n",
                "2. **SVM**: Support Vector Machine with RBF kernel\n",
                "3. **KNN**: K-Nearest Neighbors\n",
                "4. **Autoencoder**: Deep learning anomaly detection\n",
                "\n",
                "**Why Compare?**\n",
                "- Understand trade-offs (speed vs accuracy)\n",
                "- Validate our XGBoost choice\n",
                "- Explore unsupervised learning (Autoencoder)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 7.1: Prepare Benchmark Dataset\n",
                "\n",
                "**Explanation**: We use a smaller sample (50k) because SVM and KNN are computationally expensive on large datasets."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Sample for benchmark (stratified)\n",
                "df_benchmark, _ = train_test_split(\n",
                "    df_clean, \n",
                "    train_size=50000, \n",
                "    stratify=df_clean['Binary_Label'], \n",
                "    random_state=42\n",
                ")\n",
                "\n",
                "# Prepare features\n",
                "X_bench = df_benchmark.drop(label_cols, axis=1, errors='ignore')\n",
                "y_bench = df_benchmark['Binary_Label']\n",
                "\n",
                "# Split\n",
                "X_train_bench, X_test_bench, y_train_bench, y_test_bench = train_test_split(\n",
                "    X_bench, y_bench, test_size=0.3, random_state=42, stratify=y_bench\n",
                ")\n",
                "\n",
                "# Scale\n",
                "scaler_bench = StandardScaler()\n",
                "X_train_bench_scaled = scaler_bench.fit_transform(X_train_bench)\n",
                "X_test_bench_scaled = scaler_bench.transform(X_test_bench)\n",
                "\n",
                "print(f\"‚úÖ Benchmark dataset prepared\")\n",
                "print(f\"Training: {X_train_bench_scaled.shape}\")\n",
                "print(f\"Testing: {X_test_bench_scaled.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 7.2: Train and Evaluate Supervised Models\n",
                "\n",
                "**Explanation**: We train 3 supervised learning algorithms and compare their performance."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Results storage\n",
                "results = {}\n",
                "\n",
                "def train_evaluate(model, name):\n",
                "    \"\"\"Train and evaluate a model\"\"\"\n",
                "    print(f\"\\nüîÑ Training {name}...\")\n",
                "    start = time.time()\n",
                "    model.fit(X_train_bench_scaled, y_train_bench)\n",
                "    train_time = time.time() - start\n",
                "    \n",
                "    # Predict\n",
                "    y_pred = model.predict(X_test_bench_scaled)\n",
                "    \n",
                "    # Metrics\n",
                "    acc = accuracy_score(y_test_bench, y_pred)\n",
                "    f1 = f1_score(y_test_bench, y_pred)\n",
                "    prec = precision_score(y_test_bench, y_pred)\n",
                "    rec = recall_score(y_test_bench, y_pred)\n",
                "    \n",
                "    # Save model\n",
                "    filename = f\"{name.replace(' ', '_').lower()}.pkl\"\n",
                "    joblib.dump(model, filename)\n",
                "    \n",
                "    results[name] = {\n",
                "        'Time_sec': train_time,\n",
                "        'Accuracy': acc,\n",
                "        'F1-Score': f1,\n",
                "        'Precision': prec,\n",
                "        'Recall': rec,\n",
                "        'File': filename\n",
                "    }\n",
                "    \n",
                "    print(f\"‚úÖ {name} completed in {train_time:.2f}s | F1: {f1:.4f}\")\n",
                "\n",
                "# Train models\n",
                "print(\"=\"*70)\n",
                "print(\"SUPERVISED LEARNING BENCHMARK\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "# 1. Random Forest\n",
                "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
                "train_evaluate(rf, 'Random Forest')\n",
                "\n",
                "# 2. SVM\n",
                "svm = SVC(kernel='rbf', random_state=42)\n",
                "train_evaluate(svm, 'SVM')\n",
                "\n",
                "# 3. KNN\n",
                "knn = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)\n",
                "train_evaluate(knn, 'KNN')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 7.3: Train Autoencoder (Unsupervised)\n",
                "\n",
                "**Explanation**: \n",
                "- **Autoencoder** learns to compress and reconstruct NORMAL traffic\n",
                "- High reconstruction error ‚Üí Anomaly (Attack)\n",
                "- This is **unsupervised**: doesn't need attack labels for training\n",
                "- Useful for detecting **zero-day attacks** (never seen before)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"UNSUPERVISED LEARNING: AUTOENCODER\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "# Train only on normal traffic\n",
                "X_train_normal = X_train_bench_scaled[y_train_bench == 0]\n",
                "X_test_normal = X_test_bench_scaled[y_test_bench == 0]\n",
                "\n",
                "print(f\"Training on {len(X_train_normal):,} normal samples\")\n",
                "\n",
                "# Build autoencoder\n",
                "input_dim = X_train_bench_scaled.shape[1]\n",
                "\n",
                "autoencoder = Sequential([\n",
                "    # Encoder\n",
                "    Dense(32, activation='relu', input_shape=(input_dim,)),\n",
                "    Dense(16, activation='relu'),\n",
                "    Dense(8, activation='relu'),  # Bottleneck (compressed representation)\n",
                "    # Decoder\n",
                "    Dense(16, activation='relu'),\n",
                "    Dense(32, activation='relu'),\n",
                "    Dense(input_dim, activation='sigmoid')  # Reconstruction\n",
                "])\n",
                "\n",
                "autoencoder.compile(optimizer='adam', loss='mse')\n",
                "\n",
                "# Train\n",
                "print(\"\\nüîÑ Training Autoencoder...\")\n",
                "start = time.time()\n",
                "history = autoencoder.fit(\n",
                "    X_train_normal, X_train_normal,\n",
                "    epochs=20,\n",
                "    batch_size=64,\n",
                "    validation_data=(X_test_normal, X_test_normal),\n",
                "    shuffle=True,\n",
                "    verbose=0\n",
                ")\n",
                "train_time = time.time() - start\n",
                "print(f\"‚úÖ Training completed in {train_time:.2f}s\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate reconstruction error\n",
                "reconstructions = autoencoder.predict(X_test_bench_scaled, verbose=0)\n",
                "mse = np.mean(np.power(X_test_bench_scaled - reconstructions, 2), axis=1)\n",
                "\n",
                "# Set threshold (95th percentile of normal traffic error)\n",
                "normal_mse = mse[y_test_bench == 0]\n",
                "threshold = np.percentile(normal_mse, 95)\n",
                "print(f\"\\nAnomaly detection threshold: {threshold:.4f}\")\n",
                "\n",
                "# Predict: High error = Attack\n",
                "y_pred_ae = (mse > threshold).astype(int)\n",
                "\n",
                "# Evaluate\n",
                "results['Autoencoder'] = {\n",
                "    'Time_sec': train_time,\n",
                "    'Accuracy': accuracy_score(y_test_bench, y_pred_ae),\n",
                "    'F1-Score': f1_score(y_test_bench, y_pred_ae),\n",
                "    'Precision': precision_score(y_test_bench, y_pred_ae),\n",
                "    'Recall': recall_score(y_test_bench, y_pred_ae),\n",
                "    'File': 'autoencoder.h5'\n",
                "}\n",
                "\n",
                "# Save\n",
                "autoencoder.save('autoencoder.h5')\n",
                "print(f\"‚úÖ Autoencoder saved | F1: {results['Autoencoder']['F1-Score']:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 7.4: Compare All Models\n",
                "\n",
                "**Explanation**: We visualize the trade-offs between different approaches."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create comparison DataFrame\n",
                "df_results = pd.DataFrame(results).T\n",
                "df_results = df_results.sort_values(by='F1-Score', ascending=False)\n",
                "\n",
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"FINAL BENCHMARK RESULTS\")\n",
                "print(\"=\"*70)\n",
                "display(df_results)\n",
                "print(\"=\"*70)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize comparison\n",
                "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
                "\n",
                "# F1-Score comparison\n",
                "df_results['F1-Score'].plot(kind='bar', ax=axes[0], color='skyblue', edgecolor='black')\n",
                "axes[0].set_title('Performance Comparison (F1-Score)', fontsize=14, fontweight='bold')\n",
                "axes[0].set_ylabel('F1-Score')\n",
                "axes[0].set_ylim(0, 1.1)\n",
                "axes[0].tick_params(axis='x', rotation=45)\n",
                "axes[0].grid(axis='y', alpha=0.3)\n",
                "\n",
                "# Training time comparison\n",
                "df_results['Time_sec'].plot(kind='bar', ax=axes[1], color='coral', edgecolor='black')\n",
                "axes[1].set_title('Training Time Comparison', fontsize=14, fontweight='bold')\n",
                "axes[1].set_ylabel('Time (seconds)')\n",
                "axes[1].tick_params(axis='x', rotation=45)\n",
                "axes[1].grid(axis='y', alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 7.5: Key Insights\n",
                "\n",
                "**Interpretation Guide**:\n",
                "\n",
                "**Performance (F1-Score)**:\n",
                "- **Random Forest**: Usually best balance of speed and accuracy\n",
                "- **SVM**: High accuracy but slow on large datasets\n",
                "- **KNN**: Fast prediction but memory-intensive\n",
                "- **Autoencoder**: Good for unknown attacks but may have more false positives\n",
                "\n",
                "**Training Time**:\n",
                "- **KNN**: Fastest (no training, just stores data)\n",
                "- **Random Forest**: Moderate\n",
                "- **SVM**: Slowest (doesn't scale well)\n",
                "- **Autoencoder**: Depends on epochs and architecture\n",
                "\n",
                "**When to Use Each**:\n",
                "- **Random Forest/XGBoost**: Production IDS (best overall)\n",
                "- **SVM**: Small, critical systems where accuracy is paramount\n",
                "- **KNN**: Quick prototyping, small datasets\n",
                "- **Autoencoder**: Detecting novel/zero-day attacks"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üéì Summary & Next Steps\n",
                "\n",
                "### What We Accomplished\n",
                "\n",
                "‚úÖ **Phase 0**: Environment setup and library installation\n",
                "\n",
                "‚úÖ **Phase 1**: Dataset construction and cleaning\n",
                "- Loaded CICIDS2017 dataset\n",
                "- Fixed data quality issues (NaN, infinites, duplicates)\n",
                "- Cleaned and standardized features\n",
                "\n",
                "‚úÖ **Phase 2**: MITRE ATT&CK analysis\n",
                "- Mapped attacks to cybersecurity framework\n",
                "- Analyzed network characteristics\n",
                "\n",
                "‚úÖ **Phase 3**: Data preparation\n",
                "- Created binary and multi-class labels\n",
                "- Normalized features\n",
                "- Split train/test sets\n",
                "\n",
                "‚úÖ **Phase 4**: Hybrid model training\n",
                "- Trained binary detection model (XGBoost)\n",
                "- Trained multi-class classifier with SMOTE\n",
                "- Created two-stage hybrid system\n",
                "\n",
                "‚úÖ **Phase 5**: Model evaluation\n",
                "- Tested on clean data\n",
                "- Robustness testing with noise\n",
                "- Error analysis\n",
                "\n",
                "‚úÖ **Phase 6**: Real-time simulation\n",
                "- Simulated packet-by-packet processing\n",
                "- Generated real-time alerts\n",
                "\n",
                "‚úÖ **Phase 7**: Model comparison\n",
                "- Benchmarked 4 different approaches\n",
                "- Compared supervised vs unsupervised learning\n",
                "\n",
                "### Next Steps for Production\n",
                "\n",
                "1. **Deploy to Cloud**: Use the saved models in a production environment\n",
                "2. **API Development**: Create REST API for real-time predictions\n",
                "3. **Dashboard**: Build monitoring dashboard (Grafana/Kibana)\n",
                "4. **Continuous Learning**: Implement model retraining pipeline\n",
                "5. **Alert System**: Integrate with SIEM (Security Information and Event Management)\n",
                "6. **Performance Optimization**: Use model quantization for faster inference\n",
                "\n",
                "### Files Generated\n",
                "\n",
                "```\n",
                "models/\n",
                "‚îú‚îÄ‚îÄ model1_binary.pkl           # Binary detection model\n",
                "‚îú‚îÄ‚îÄ model2_multiclass.pkl       # Multi-class classifier\n",
                "‚îú‚îÄ‚îÄ hybrid_ids_system.pkl       # Complete hybrid system\n",
                "‚îú‚îÄ‚îÄ scaler.pkl                  # Feature scaler\n",
                "‚îú‚îÄ‚îÄ label_encoder.pkl           # Label encoder\n",
                "‚îú‚îÄ‚îÄ random_forest.pkl           # Benchmark: Random Forest\n",
                "‚îú‚îÄ‚îÄ svm.pkl                     # Benchmark: SVM\n",
                "‚îú‚îÄ‚îÄ knn.pkl                     # Benchmark: KNN\n",
                "‚îî‚îÄ‚îÄ autoencoder.h5              # Benchmark: Autoencoder\n",
                "```\n",
                "\n",
                "### Resources\n",
                "\n",
                "- **CICIDS2017 Dataset**: https://www.kaggle.com/datasets/cicdataset/cicids2017\n",
                "- **MITRE ATT&CK**: https://attack.mitre.org/\n",
                "- **XGBoost Documentation**: https://xgboost.readthedocs.io/\n",
                "- **SMOTE Paper**: https://arxiv.org/abs/1106.1813\n",
                "\n",
                "---\n",
                "\n",
                "**üéâ Congratulations! You've built a complete hybrid IDS system! üéâ**"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}