"""
Script d'exemple pour utiliser les fonctions de preprocessing
Utilisez ce script comme r√©f√©rence pour votre workflow Kaggle
"""

import pandas as pd
import sys
import os

# Ajouter le r√©pertoire parent au path pour importer src
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.preprocessing import (
    clean_cicids2017,
    map_labels,
    encode_labels,
    prepare_features,
    verify_dataset,
    ATTACK_CATEGORIES
)


def example_workflow(input_file, output_dir='data/processed'):
    """
    Exemple de workflow complet de preprocessing
    
    Args:
        input_file (str): Chemin vers le fichier CSV brut
        output_dir (str): R√©pertoire de sortie
    """
    print("=" * 70)
    print("WORKFLOW DE PREPROCESSING CICIDS2017")
    print("=" * 70)
    
    # 1. Charger le dataset
    print(f"\nüìÇ √âtape 1: Chargement du dataset")
    print(f"   Fichier: {input_file}")
    df = pd.read_csv(input_file)
    print(f"   ‚úÖ Charg√©: {df.shape}")
    
    # 2. Nettoyer
    print(f"\nüßπ √âtape 2: Nettoyage du dataset")
    df_clean = clean_cicids2017(df, verbose=True)
    
    # 3. Mapper les labels
    print(f"\nüè∑Ô∏è  √âtape 3: Mapping des labels")
    df_clean = map_labels(df_clean, label_col='Attack Type')
    print(f"   ‚úÖ Labels mapp√©s vers cat√©gories")
    print(f"\n   Distribution des cat√©gories:")
    print(df_clean['Attack_Category'].value_counts())
    
    # 4. Encoder les labels
    print(f"\nüî¢ √âtape 4: Encodage num√©rique")
    encoder_path = os.path.join(output_dir, 'label_encoder.pkl')
    df_clean, le = encode_labels(df_clean, save_path=encoder_path)
    
    # 5. V√©rifier la qualit√©
    print(f"\n‚úÖ √âtape 5: V√©rification de la qualit√©")
    verify_dataset(df_clean)
    
    # 6. Sauvegarder le dataset nettoy√©
    print(f"\nüíæ √âtape 6: Sauvegarde")
    os.makedirs(output_dir, exist_ok=True)
    output_file = os.path.join(output_dir, 'cicids2017_cleaned.csv')
    df_clean.to_csv(output_file, index=False)
    print(f"   ‚úÖ Dataset sauvegard√©: {output_file}")
    
    # 7. Pr√©parer les features pour ML
    print(f"\nüéØ √âtape 7: Pr√©paration des features")
    scaler_path = os.path.join(output_dir, 'scaler.pkl')
    X, y, scaler = prepare_features(df_clean, scale=True, scaler_path=scaler_path)
    
    # Sauvegarder X et y
    import numpy as np
    np.save(os.path.join(output_dir, 'X_scaled.npy'), X.values)
    np.save(os.path.join(output_dir, 'y.npy'), y.values)
    print(f"   ‚úÖ Features sauvegard√©es: X_scaled.npy, y.npy")
    
    print("\n" + "=" * 70)
    print("üéâ PREPROCESSING TERMIN√â AVEC SUCC√àS!")
    print("=" * 70)
    print(f"\nFichiers g√©n√©r√©s dans '{output_dir}':")
    print(f"   - cicids2017_cleaned.csv (dataset complet)")
    print(f"   - X_scaled.npy (features normalis√©es)")
    print(f"   - y.npy (labels encod√©s)")
    print(f"   - scaler.pkl (scaler pour normalisation)")
    print(f"   - label_encoder.pkl (encodeur de labels)")
    print("\n‚úÖ Pr√™t pour l'entra√Ænement des mod√®les!")
    print("=" * 70)
    
    return df_clean, X, y


def quick_example():
    """
    Exemple rapide pour tester les fonctions
    """
    print("=" * 70)
    print("EXEMPLE RAPIDE DE PREPROCESSING")
    print("=" * 70)
    
    # Cr√©er un petit dataset d'exemple
    import numpy as np
    
    data = {
        'Destination Port': [80, 443, 22, 80, 443],
        'Flow Duration': [1000, 2000, np.inf, 1500, 2500],
        'Total Fwd Packets': [10, 20, 15, 12, 18],
        'Total Length of Fwd Packets': [500, 1000, 750, 600, 900],
        'Flow Bytes/s': [500.0, 500.0, np.nan, 400.0, 360.0],
        'Flow Packets/s': [10.0, 10.0, np.nan, 8.0, 7.2],
        'Attack Type': ['BENIGN', 'DoS Hulk', 'BENIGN', 'PortScan', 'DDoS']
    }
    
    df = pd.DataFrame(data)
    print("\nüìä Dataset d'exemple:")
    print(df)
    
    # Nettoyer
    print("\nüßπ Nettoyage...")
    df_clean = clean_cicids2017(df, verbose=True)
    
    # Mapper
    print("\nüè∑Ô∏è  Mapping des labels...")
    df_clean = map_labels(df_clean)
    
    # Encoder
    print("\nüî¢ Encodage...")
    df_clean, le = encode_labels(df_clean)
    
    print("\nüìä Dataset final:")
    print(df_clean[['Attack Type', 'Attack_Category', 'Label_Encoded']])
    
    print("\n‚úÖ Exemple termin√©!")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='Preprocessing CICIDS2017')
    parser.add_argument('--input', type=str, help='Chemin vers le fichier CSV')
    parser.add_argument('--output', type=str, default='data/processed', 
                       help='R√©pertoire de sortie')
    parser.add_argument('--example', action='store_true', 
                       help='Ex√©cuter l\'exemple rapide')
    
    args = parser.parse_args()
    
    if args.example:
        quick_example()
    elif args.input:
        example_workflow(args.input, args.output)
    else:
        print("Usage:")
        print("  python scripts/preprocessing_example.py --input data/raw/Monday.csv")
        print("  python scripts/preprocessing_example.py --example")
