"""
Utilitaires pour le preprocessing du dataset CICIDS2017
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, StandardScaler
import joblib
import os


# Mapping des labels vers cat√©gories d'attaques
# Pour dataset pr√©-nettoy√© (7 cat√©gories)
ATTACK_CATEGORIES_PRECLEANED = {
    'Normal Traffic': 'Normal',
    'Port Scanning': 'Reconnaissance',
    'Web Attacks': 'Web_Attack',
    'Brute Force': 'Brute_Force',
    'DDoS': 'DoS_DDoS',
    'Bots': 'Botnet',
    'DoS': 'DoS_DDoS'
}

# Mapping pour dataset original (15 classes)
ATTACK_CATEGORIES_ORIGINAL = {
    'BENIGN': 'Normal',
    'FTP-Patator': 'Brute_Force',
    'SSH-Patator': 'Brute_Force',
    'Web Attack ‚Äì Brute Force': 'Brute_Force',
    'DoS slowloris': 'DoS_DDoS',
    'DoS Slowhttptest': 'DoS_DDoS',
    'DoS Hulk': 'DoS_DDoS',
    'DoS GoldenEye': 'DoS_DDoS',
    'DDoS': 'DoS_DDoS',
    'Web Attack ‚Äì XSS': 'Web_Attack',
    'Web Attack ‚Äì SQL Injection': 'Web_Attack',
    'PortScan': 'Reconnaissance',
    'Bot': 'Botnet',
    'Infiltration': 'Advanced_Threat',
    'Heartbleed': 'Advanced_Threat'
}

# Par d√©faut, utiliser le mapping pr√©-nettoy√©
ATTACK_CATEGORIES = ATTACK_CATEGORIES_PRECLEANED


def clean_cicids2017(df, verbose=True):
    """
    Nettoie le dataset CICIDS2017
    
    Args:
        df (pd.DataFrame): DataFrame √† nettoyer
        verbose (bool): Afficher les messages de progression
    
    Returns:
        pd.DataFrame: DataFrame nettoy√©
    """
    if verbose:
        print("üßπ Nettoyage en cours...")
        print(f"Shape initiale: {df.shape}")
        print(f"Colonnes: {len(df.columns)}")
    
    # 1. Nettoyer les noms de colonnes (enlever espaces au d√©but/fin)
    df.columns = df.columns.str.strip()
    if verbose:
        print("‚úÖ Noms de colonnes nettoy√©s")
    
    # 2. Supprimer les duplications
    initial_rows = len(df)
    df = df.drop_duplicates()
    duplicates_removed = initial_rows - len(df)
    if verbose:
        print(f"‚úÖ Duplications supprim√©es: {duplicates_removed}")
    
    # 3. G√©rer les valeurs infinies
    df.replace([np.inf, -np.inf], np.nan, inplace=True)
    if verbose:
        print("‚úÖ Valeurs infinies remplac√©es par NaN")
    
    # 4. G√©rer les NaN
    nan_before = df.isnull().sum().sum()
    
    # Remplir avec la m√©diane pour les colonnes num√©riques (sauf Attack Type)
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    for col in numeric_cols:
        if df[col].isnull().any():
            df[col].fillna(df[col].median(), inplace=True)
    
    nan_after = df.isnull().sum().sum()
    if verbose:
        print(f"‚úÖ NaN trait√©s: {nan_before} ‚Üí {nan_after}")
    
    # 5. Corriger les valeurs n√©gatives incorrectes
    positive_cols = ['Flow Duration', 'Total Fwd Packets', 'Total Length of Fwd Packets']
    for col in positive_cols:
        if col in df.columns:
            negative_count = (df[col] < 0).sum()
            if negative_count > 0:
                df.loc[df[col] < 0, col] = 0
                if verbose:
                    print(f"‚úÖ {col}: {negative_count} valeurs n√©gatives corrig√©es")
    
    if verbose:
        print(f"\nüéâ Nettoyage termin√©!")
        print(f"Shape finale: {df.shape}")
    
    return df


def create_binary_labels(df, label_col='Attack Type', normal_label='Normal Traffic'):
    """
    Cr√©e des labels binaires : 0 = Normal, 1 = Attaque
    
    Args:
        df (pd.DataFrame): DataFrame contenant les labels
        label_col (str): Nom de la colonne des labels
        normal_label (str): Label repr√©sentant le trafic normal
    
    Returns:
        pd.DataFrame: DataFrame avec colonne 'Binary_Label' ajout√©e
    """
    df['Binary_Label'] = (df[label_col] != normal_label).astype(int)
    
    print(f"Distribution binaire:")
    print(f"  0 (Normal): {(df['Binary_Label'] == 0).sum():,}")
    print(f"  1 (Attaque): {(df['Binary_Label'] == 1).sum():,}")
    
    return df


def map_labels(df, label_col='Attack Type', mapping=ATTACK_CATEGORIES):
    """
    Mappe les labels originaux vers des cat√©gories d'attaques
    
    Args:
        df (pd.DataFrame): DataFrame contenant les labels
        label_col (str): Nom de la colonne des labels
        mapping (dict): Dictionnaire de mapping
    
    Returns:
        pd.DataFrame: DataFrame avec colonne 'Attack_Category' ajout√©e
    """
    df['Attack_Category'] = df[label_col].map(mapping)
    
    # V√©rifier s'il y a des labels non mapp√©s
    unmapped = df['Attack_Category'].isnull().sum()
    if unmapped > 0:
        print(f"‚ö†Ô∏è Attention: {unmapped} labels non mapp√©s")
        print("Labels non mapp√©s:")
        print(df[df['Attack_Category'].isnull()][label_col].unique())
    
    return df


def encode_labels(df, category_col='Attack_Category', save_path=None):
    """
    Encode les cat√©gories d'attaques en valeurs num√©riques
    
    Args:
        df (pd.DataFrame): DataFrame avec les cat√©gories
        category_col (str): Nom de la colonne des cat√©gories
        save_path (str): Chemin pour sauvegarder l'encodeur (optionnel)
    
    Returns:
        tuple: (DataFrame avec 'Label_Encoded', LabelEncoder)
    """
    le = LabelEncoder()
    df['Label_Encoded'] = le.fit_transform(df[category_col])
    
    # Afficher le mapping
    print("Mapping num√©rique:")
    for i, label in enumerate(le.classes_):
        count = (df['Label_Encoded'] == i).sum()
        print(f"{i}: {label} ({count} instances)")
    
    # Sauvegarder l'encodeur si demand√©
    if save_path:
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        joblib.dump(le, save_path)
        print(f"\n‚úÖ Encodeur sauvegard√©: {save_path}")
    
    return df, le


def prepare_features(df, label_cols=['Attack Type', 'Attack_Category', 'Label_Encoded'], 
                     scale=True, scaler_path=None):
    """
    Pr√©pare les features pour l'entra√Ænement
    
    Args:
        df (pd.DataFrame): DataFrame nettoy√©
        label_cols (list): Colonnes de labels √† exclure des features
        scale (bool): Normaliser les features
        scaler_path (str): Chemin pour sauvegarder le scaler (optionnel)
    
    Returns:
        tuple: (X, y, scaler ou None)
    """
    # S√©parer features et labels
    feature_cols = [col for col in df.columns if col not in label_cols]
    X = df[feature_cols]
    y = df['Label_Encoded']
    
    print(f"Features shape: {X.shape}")
    print(f"Labels shape: {y.shape}")
    
    # Normaliser si demand√©
    scaler = None
    if scale:
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        X = pd.DataFrame(X_scaled, columns=X.columns, index=X.index)
        print("‚úÖ Features normalis√©es")
        
        # Sauvegarder le scaler si demand√©
        if scaler_path:
            os.makedirs(os.path.dirname(scaler_path), exist_ok=True)
            joblib.dump(scaler, scaler_path)
            print(f"‚úÖ Scaler sauvegard√©: {scaler_path}")
    
    return X, y, scaler


def load_and_preprocess(file_path, clean=True, map_labels_flag=True, 
                        encode=True, prepare=True, verbose=True):
    """
    Pipeline complet de preprocessing
    
    Args:
        file_path (str): Chemin vers le fichier CSV
        clean (bool): Nettoyer le dataset
        map_labels_flag (bool): Mapper les labels
        encode (bool): Encoder les labels
        prepare (bool): Pr√©parer les features
        verbose (bool): Afficher les messages
    
    Returns:
        dict: Dictionnaire contenant df, X, y, le, scaler
    """
    # Charger
    if verbose:
        print(f"üìÇ Chargement de: {file_path}")
    df = pd.read_csv(file_path)
    
    if verbose:
        print(f"Shape initiale: {df.shape}")
    
    # Nettoyer
    if clean:
        df = clean_cicids2017(df, verbose=verbose)
    
    # Mapper les labels
    if map_labels_flag:
        df = map_labels(df)
    
    # Encoder
    le = None
    if encode:
        df, le = encode_labels(df)
    
    # Pr√©parer les features
    X, y, scaler = None, None, None
    if prepare:
        X, y, scaler = prepare_features(df)
    
    return {
        'df': df,
        'X': X,
        'y': y,
        'label_encoder': le,
        'scaler': scaler
    }


def verify_dataset(df):
    """
    V√©rifie la qualit√© du dataset nettoy√©
    
    Args:
        df (pd.DataFrame): DataFrame √† v√©rifier
    """
    print("=" * 60)
    print("V√âRIFICATION DU DATASET")
    print("=" * 60)
    
    print(f"\n1. Shape: {df.shape}")
    
    print(f"\n2. Valeurs manquantes:")
    nan_count = df.isnull().sum().sum()
    print(f"   Total NaN: {nan_count}")
    if nan_count > 0:
        print("   ‚ö†Ô∏è Des valeurs NaN sont pr√©sentes!")
    else:
        print("   ‚úÖ Aucune valeur NaN")
    
    print(f"\n3. Valeurs infinies:")
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    inf_count = np.isinf(df[numeric_cols]).sum().sum()
    print(f"   Total infinis: {inf_count}")
    if inf_count > 0:
        print("   ‚ö†Ô∏è Des valeurs infinies sont pr√©sentes!")
    else:
        print("   ‚úÖ Aucune valeur infinie")
    
    print(f"\n4. Duplications:")
    dup_count = df.duplicated().sum()
    print(f"   Total duplications: {dup_count}")
    if dup_count > 0:
        print("   ‚ö†Ô∏è Des duplications sont pr√©sentes!")
    else:
        print("   ‚úÖ Aucune duplication")
    
    if 'Attack_Category' in df.columns:
        print(f"\n5. Distribution des cat√©gories:")
        print(df['Attack_Category'].value_counts())
    
    print("\n" + "=" * 60)
    
    # Score de qualit√©
    issues = (nan_count > 0) + (inf_count > 0) + (dup_count > 0)
    if issues == 0:
        print("‚úÖ Dataset de haute qualit√© - Pr√™t pour l'entra√Ænement!")
    elif issues == 1:
        print("‚ö†Ô∏è Dataset acceptable - Quelques probl√®mes mineurs")
    else:
        print("‚ùå Dataset probl√©matique - Nettoyage suppl√©mentaire requis")
    
    print("=" * 60)


if __name__ == "__main__":
    # Exemple d'utilisation
    print("Module de preprocessing CICIDS2017")
    print("Importez ce module dans vos notebooks:")
    print("  from src.preprocessing import clean_cicids2017, map_labels, encode_labels")
